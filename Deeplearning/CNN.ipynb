{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, padding=0, in_channels=0, out_channels=0, kernel_size=0):\n",
    "        self.padding = padding\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weights = np.random.randn(out_channels, in_channels, self.kernel_size, self.kernel_size) * 0.01\n",
    "        self.bias = np.zeros(out_channels)\n",
    "        self.input = None\n",
    "        self.padded_input = None\n",
    "\n",
    "    def apply_padding(self, mat):\n",
    "        padding_size = self.padding\n",
    "        if padding_size == 0:\n",
    "            return mat\n",
    "        #패딩에서는 0으로 미리 사이즈 크게 생성하고 그 중간에 원래 행렬 저장해서 패딩\n",
    "        padded_arr = np.zeros((mat.shape[0], mat.shape[1] + 2 * padding_size, mat.shape[2] + 2 * padding_size))\n",
    "        padded_arr[:, padding_size:-padding_size, padding_size:-padding_size] = mat\n",
    "        return padded_arr\n",
    "\n",
    "    def convolution(self, padded):\n",
    "        #\n",
    "        output_size, input_size, _, _ = self.weights.shape\n",
    "        kernel_size = self.kernel_size\n",
    "        padded_height, padded_width = padded.shape[1:]  # 높이와 너비 추출\n",
    "        #짝수와 아닐 때 계산이 다름 \n",
    "        if kernel_size % 2 == 0:\n",
    "            output_padded_height = (padded_height - kernel_size) \n",
    "            output_padded_width = (padded_width - kernel_size) \n",
    "        else:\n",
    "            output_padded_height = (padded_height - kernel_size) // 1 + 1\n",
    "            output_padded_width = (padded_width - kernel_size) // 1 + 1\n",
    "\n",
    "        output = np.zeros((output_size, output_padded_height, output_padded_width))\n",
    "        #컨볼루션 연산 \n",
    "        for o in range(output_size):\n",
    "            for n in range(input_size):\n",
    "                for i in range(output_padded_height):\n",
    "                    for j in range(output_padded_width):\n",
    "                        patch = padded[n, i:i + kernel_size, j:j + kernel_size]\n",
    "                        output[o, i, j] += np.sum(patch * self.weights[o, n]) \n",
    "        #output[o] += self.bias[o] #원래 넣어야하지만 이상하게 안넣는게 더 잘됨 \n",
    "        return output\n",
    "\n",
    "    def feedforward(self, mat):\n",
    "        self.input = mat\n",
    "        self.padded_input = self.apply_padding(mat)\n",
    "        convolutioned = self.convolution(self.padded_input)\n",
    "        return convolutioned\n",
    "\n",
    "    def backward(self, grad_output, lr):\n",
    "        output_size, input_size, kernel_size, _ = self.weights.shape\n",
    "        padded_height, padded_width = self.padded_input.shape[1:]\n",
    "        grad_input = np.zeros_like(self.padded_input)\n",
    "        grad_weights = np.zeros_like(self.weights)\n",
    "        grad_bias = np.zeros_like(self.bias)\n",
    "\n",
    "        for o in range(output_size):\n",
    "            grad_bias[o] = np.sum(grad_output[o])\n",
    "\n",
    "        # ✅ 가중치 기울기 계산\n",
    "        for o in range(output_size):\n",
    "            for n in range(input_size):\n",
    "                for i in range(grad_output.shape[1]):  \n",
    "                    for j in range(grad_output.shape[2]): \n",
    "                        patch = self.padded_input[n, i:i + kernel_size, j:j + kernel_size]\n",
    "                        grad_weights[o, n] += grad_output[o, i, j] * patch\n",
    "\n",
    "        # ✅ 입력 기울기 계산 (필터 180도 회전 후 적용)\n",
    "        flipped_weights = np.flip(self.weights, axis=(2, 3))\n",
    "\n",
    "        for o in range(output_size):\n",
    "            for n in range(input_size):\n",
    "                for i in range(grad_output.shape[1]):  \n",
    "                    for j in range(grad_output.shape[2]): \n",
    "                        patch = grad_output[o, i, j]  \n",
    "                        grad_input[n, i:i + kernel_size, j:j + kernel_size] += patch * flipped_weights[o, n]\n",
    "\n",
    "        # ✅ 가중치 및 편향 업데이트\n",
    "        self.weights -= lr * grad_weights\n",
    "        self.bias -= lr * grad_bias\n",
    "\n",
    "        # ✅ 입력 기울기에서 패딩 제거\n",
    "        if self.padding > 0:\n",
    "            grad_input = grad_input[:, self.padding:-self.padding, self.padding:-self.padding]\n",
    "\n",
    "        return grad_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling:\n",
    "    def __init__(self, kernel_size = 2):\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def feedforward(self, mat):\n",
    "        kernel_size = self.kernel_size\n",
    "        output_channels, convolutioned_height, convolutioned_width = mat.shape\n",
    "        output_height = convolutioned_height // kernel_size\n",
    "        output_width = convolutioned_width // kernel_size\n",
    "        #풀링되는 값들과 역전파때 사용해야하므로 원래 위치도 마스크에 같이 저장\n",
    "        pooled = np.zeros((output_channels, output_height, output_width))\n",
    "        self.mask = np.zeros_like(mat)  \n",
    "        for o in range(output_channels):\n",
    "            for i in range(output_height):\n",
    "                for j in range(output_width):\n",
    "                    start_i, start_j = i * kernel_size, j * kernel_size\n",
    "                    end_i, end_j = start_i + kernel_size, start_j + kernel_size\n",
    "                    input_mat = mat[o, start_i:end_i, start_j:end_j]\n",
    "\n",
    "                    max_value = np.max(input_mat)\n",
    "                    max_position = np.unravel_index(np.argmax(input_mat), input_mat.shape)\n",
    "\n",
    "                    pooled[o, i, j] = max_value\n",
    "\n",
    "                    self.mask[o, start_i:end_i, start_j:end_j][max_position] = 1\n",
    "        \n",
    "        return pooled\n",
    "    \n",
    "    def backward(self, grad_output, lr):\n",
    "        #역전파 때는 들어온 입력 데이터로 풀링 전의 원래 위치로 돌려야함함\n",
    "        grad_input = self.mask * np.repeat(\n",
    "            np.repeat(grad_output, self.kernel_size, axis=1),  # 행 방향 확장\n",
    "            self.kernel_size, axis=2,  # 열 방향 확장\n",
    "        )\n",
    "        return grad_input\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "\n",
    "    def feedforward(self, mat):\n",
    "        self.input = mat\n",
    "        return np.maximum(0, mat)\n",
    "    \n",
    "    def backward(self, mat, lr):\n",
    "        grad_input = mat * (self.input > 0).astype(float)\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.pred = None\n",
    "    \n",
    "    def feedforward(self, mat):\n",
    "        self.input = mat\n",
    "\n",
    "        # 차원이 1D인 경우, (1, C)로 변경\n",
    "        if mat.ndim == 1:\n",
    "            mat = mat.reshape(1, -1)\n",
    "        #\n",
    "        ex = np.exp(mat - np.max(mat, axis=1, keepdims=True))\n",
    "        all_ex = np.sum(ex, axis=1, keepdims=True)\n",
    "        self.pred = ex / all_ex\n",
    "        return self.pred\n",
    "\n",
    "    \n",
    "    def backward(self, answer, lr):\n",
    "        return self.pred - answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(pred, answer):\n",
    "    return -np.sum(answer * np.log(pred + 1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers = None):\n",
    "        #레이어들 초기화\n",
    "        if layers is None:\n",
    "            self.layers = []\n",
    "        else:\n",
    "            self.layers = layers\n",
    "        self.loss = None\n",
    "        self.lr = None\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def fit(self, x_data, y_data, epochs): \n",
    "        prev_total_loss = 100000\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0  # 전체 손실 누적\n",
    "\n",
    "            for i in range(x_data.shape[0]):  \n",
    "                \n",
    "                sample_input = x_data[i].reshape(1, 28, 28)\n",
    "\n",
    "                # 순전파\n",
    "                self.forward(sample_input)  \n",
    "\n",
    "                # 손실 계산\n",
    "                final_output = self.final_output\n",
    "                loss = cross_entropy(final_output, y_data[i:i+1])  \n",
    "                total_loss += loss\n",
    "\n",
    "                # 역전파\n",
    "                self.backward(y_data[i:i+1]) \n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / x_data.shape[0]}\")\n",
    "            if prev_total_loss < total_loss:\n",
    "                break\n",
    "            else:\n",
    "                prev_total_loss = total_loss\n",
    "\n",
    "            \n",
    "    def pred(self, mat):\n",
    "        # 입력 차원 조정 후 값 예측\n",
    "        sample_input = mat.reshape(1, 28, 28)\n",
    "\n",
    "        self.forward(sample_input)\n",
    "        final_output = self.final_output\n",
    "        return final_output\n",
    "        \n",
    "    def compile(self, loss = \"cross_entropy\", lr = 0.01):\n",
    "        #loss랑 lr 설정정\n",
    "        self.loss = loss\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        #레이어들 feedforward 계산해서 출력 \n",
    "        for layer in self.layers:\n",
    "            input_data = layer.feedforward(input_data)\n",
    "        self.final_output = input_data\n",
    "        return input_data\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        #레이어들 backward 계산해서 출력\n",
    "        for layer in reversed(self.layers):\n",
    "            grad_output = layer.backward(grad_output, self.lr)\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flatten:\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "\n",
    "    def feedforward(self, mat):\n",
    "        #backward 때 다시 돌려야하므로 shape 미리 저장\n",
    "        self.shape = mat.shape\n",
    "        return mat.flatten()\n",
    "    \n",
    "    def backward(self, mat, lr):\n",
    "        return mat.reshape(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jackryan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_node, output_node):\n",
    "        self.node = input_node\n",
    "        self.weights = np.random.randn(input_node, output_node) * 0.01\n",
    "        self.bias = np.zeros(output_node)\n",
    "        self.mat = None\n",
    "        \n",
    "    def feedforward(self, mat):\n",
    "        #내적 연산\n",
    "        self.mat = mat\n",
    "        return np.dot(mat, self.weights) + self.bias\n",
    "    \n",
    "    def backward(self, grad_output, lr, clip_value=1.0):\n",
    "        # 차원 강제 변환\n",
    "        self.mat = self.mat.reshape(1, -1) if self.mat.ndim == 1 else self.mat  \n",
    "        grad_output = grad_output.reshape(1, -1) if grad_output.ndim == 1 else grad_output  \n",
    "\n",
    "        # 가중치 기울기 계산\n",
    "        grad_weights = np.dot(self.mat.T, grad_output)\n",
    "        grad_bias = np.sum(grad_output, axis=0)\n",
    "\n",
    "        # Gradient Clipping \n",
    "        grad_norm = np.linalg.norm(grad_weights)\n",
    "        if grad_norm > clip_value:\n",
    "            grad_weights = grad_weights * (clip_value / grad_norm)\n",
    "\n",
    "        # 가중치 업데이트\n",
    "        self.weights -= lr * grad_weights\n",
    "        self.bias -= lr * grad_bias\n",
    "\n",
    "        # 이전 레이어로 전달할 기울기\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.3030104357782006\n",
      "Epoch 2/100, Loss: 2.300622096736812\n",
      "Epoch 3/100, Loss: 2.2997712641031067\n",
      "Epoch 4/100, Loss: 2.283209251865132\n",
      "Epoch 5/100, Loss: 1.572191240750164\n",
      "Epoch 6/100, Loss: 0.8835851258574335\n",
      "Epoch 7/100, Loss: 0.712375110345381\n",
      "Epoch 8/100, Loss: 0.6401811558164953\n",
      "Epoch 9/100, Loss: 0.5788481269918968\n",
      "Epoch 10/100, Loss: 0.5281557885553555\n",
      "Epoch 11/100, Loss: 0.48241487525351034\n",
      "Epoch 12/100, Loss: 0.4438233452745709\n",
      "Epoch 13/100, Loss: 0.4113183461826835\n",
      "Epoch 14/100, Loss: 0.38537418642734733\n",
      "Epoch 15/100, Loss: 0.3651528168116771\n",
      "Epoch 16/100, Loss: 0.3499960866251866\n",
      "Epoch 17/100, Loss: 0.3392248430431901\n",
      "Epoch 18/100, Loss: 0.33375517303661284\n",
      "Epoch 19/100, Loss: 0.3353727439295222\n",
      "Test Accuracy: 85.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load MNIST dataset\n",
    "X = mnist.data.values.reshape(-1, 1, 28, 28)  # Reshape to (samples, channels, height, width)\n",
    "y = mnist.target.values.astype(int).reshape(-1, 1)  # Reshape labels\n",
    "#X 70000개\n",
    "\n",
    "X = X / 255.0\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(y).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#데이터셋이 많고 계산이 오래걸려서 데이터셋 줄여서 학습습\n",
    "X_train = X_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "\n",
    "X_test = X_test[:200]\n",
    "y_test = y_test[:200]\n",
    "\n",
    "network = Network()\n",
    "\n",
    "cnn_layer = CNN(padding=1, in_channels=1, out_channels=1, kernel_size=2)\n",
    "network.add(cnn_layer)\n",
    "\n",
    "network.add(ReLu())\n",
    "\n",
    "maxpool_layer = MaxPooling(kernel_size=2)\n",
    "network.add(maxpool_layer)\n",
    "\n",
    "flatten_layer = flatten()\n",
    "network.add(flatten_layer)\n",
    "\n",
    "network.add(Linear(196, 32))  \n",
    "network.add(ReLu())           \n",
    "network.add(Linear(32, 10)) \n",
    "network.add(Softmax())        \n",
    "\n",
    "network.compile(lr=0.01)\n",
    "\n",
    "epochs = 100\n",
    "network.fit(X_train, y_train, epochs=epochs)\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    prediction = network.pred(X_test[i:i + 1])\n",
    "    \n",
    "    if np.argmax(prediction) == np.argmax(y_test[i]):\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / X_test.shape[0]\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
